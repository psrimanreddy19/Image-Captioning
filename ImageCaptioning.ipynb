{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImageCaptioning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQtb50-5Ee-j"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Model, load_model\n",
        "from keras.preprocessing import image\n",
        "import time\n",
        "import pickle\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VEvO6R8nJ3r"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iABNljtrFLDC"
      },
      "source": [
        "import pandas as pd\n",
        "dataset = pd.read_csv('/content/drive/MyDrive/drive-download-20210515T180709Z-001/Flickr8k_text/Flickr8k.lemma.token.txt',delimiter='\\t',header=None) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhJeca5pFLFm"
      },
      "source": [
        "print(dataset.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7e2vNMdCFLH_"
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBBkqlG-lmnv"
      },
      "source": [
        "print(dataset[0][3])\n",
        "print(dataset[1][3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7u4IWFazq-w"
      },
      "source": [
        "# Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nf35mMWRFLKi"
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "corpus = []\n",
        "for i in range(0, dataset.shape[0]):\n",
        "    cap = re.sub('[^a-zA-Z]', ' ', dataset[1][i])  #Removed all other characters except alphabets\n",
        "    cap = cap.lower()                              #Converted to lower case\n",
        "    cap = cap.split()                               \n",
        "    cap=[word for word in cap if len(word)>1]      #Removed single letter words\n",
        "    cap = ' '.join(cap)                            # Joined with spaces\n",
        "    cap= '<startseq> '+cap+' <endseq>'\n",
        "    corpus.append(cap)                             #list of captions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6vcjRNsFLO9"
      },
      "source": [
        "for i in range(50): print(corpus[i:i+1])\n",
        "print(len(corpus))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27she8ByFLWF"
      },
      "source": [
        "i=0\n",
        "while i < dataset.shape[0]:\n",
        "  dataset[0][i]=dataset[0][i].split('.')[0]        #Removed characters after '.'\n",
        "  i=i+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_6nWwmdFLZb"
      },
      "source": [
        "print(dataset.head)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-04iRQeb4W6"
      },
      "source": [
        "type(dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVsDEZVpFLUa"
      },
      "source": [
        "from collections import defaultdict\n",
        "new_dict= defaultdict(lambda : [])          #Created a dictionary with image ids as key and captions as value\n",
        "i=0\n",
        "while i <len(corpus):\n",
        "  # print(dataset[0][i])\n",
        "  new_dict[dataset[0][i]].append(corpus[i])\n",
        "  i=i+1                                                     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzOFJLTwFLS8"
      },
      "source": [
        "print(len(new_dict))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yiq86iLDFLNT"
      },
      "source": [
        "print(new_dict['2513260012_03d33305cf'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwmWi4a1GSxD"
      },
      "source": [
        "all_vocab = []              #A list of all the words in the captions\n",
        "\n",
        "for key in new_dict.keys():\n",
        "    [ all_vocab.append(i) for des in new_dict[key] for i in des.split()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e34Gq7V4GS1Z"
      },
      "source": [
        "print(\"total words appearing : \" , len(all_vocab))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOvzk54BGS-t"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "counter = Counter(all_vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iNdTlfjGS8h"
      },
      "source": [
        "dic_ = dict(counter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8ilZ0w_GS59"
      },
      "source": [
        "sorted_dic = sorted(dic_.items(), key = lambda x: x[1], reverse=True)   #List with words and their corresponding frequency"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZhk3XY1Algo"
      },
      "source": [
        "print(len(sorted_dic))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIOEfylD95X5"
      },
      "source": [
        "for i in range(100):\n",
        "  print(sorted_dic[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaIwH8cDGSuW"
      },
      "source": [
        "threshold_value = 10\n",
        "\n",
        "d = [(x) for x in sorted_dic if x[1]>threshold_value]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJWRFlimFLAe"
      },
      "source": [
        "len(d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvYKzykjGuox"
      },
      "source": [
        "all_vocab = [x[0] for x in d]                       #Updating all_vocab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1KhOnusGusJ"
      },
      "source": [
        "len(all_vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTgbzIVRG7M5"
      },
      "source": [
        "f = open('new_dict.txt', 'w')\n",
        "f.write(str(new_dict))\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whgM-r9NG7Rr"
      },
      "source": [
        "with open('/content/drive/MyDrive/drive-download-20210515T180709Z-001/Flickr8k_text/Flickr_8k.trainImages.txt') as f:\n",
        "  train=f.read()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1SdEc8DG7WP"
      },
      "source": [
        "train = [e[:-4] for e in train.split('\\n')[:-1]]                                #train image ids"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8eukcB6LOFV"
      },
      "source": [
        "for i in range(len(train)):\n",
        "  if i>10:\n",
        "    break\n",
        "  print(train[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jA3ZkkzpG7QW"
      },
      "source": [
        "with open('/content/drive/MyDrive/drive-download-20210515T180709Z-001/Flickr8k_text/Flickr_8k.testImages.txt')as f:\n",
        "  test=f.read()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sQ3KnoZG7Ku"
      },
      "source": [
        "test = [e[:-4] for e in test.split('\\n')[:-1]]                                    #test image ids"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQ-mm77tpw8H"
      },
      "source": [
        "for i in range(len(test)):\n",
        "  if i>10:\n",
        "    break\n",
        "  print(test[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPr_iAJpIA77"
      },
      "source": [
        "train_descriptions = {}                                                           #dictionary with keys as image ids and values as corresponding captions\n",
        "for t in train:\n",
        "    train_descriptions[t] = []\n",
        "    for cap in new_dict[t]:\n",
        "        train_descriptions[t].append(cap)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTrb5ouCyadj"
      },
      "source": [
        "print(train_descriptions['2903617548_d3e38d7f88'][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EixKVYMyGL58"
      },
      "source": [
        "images='/content/drive/MyDrive/drive-download-20210515T180709Z-001/Flicker8k_Images/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kt05gjhgyPgg"
      },
      "source": [
        "img_id='2903617548_d3e38d7f88.jpg'\n",
        "path = images + img_id\n",
        "img = plt.imread(path)\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "for i in range(5):\n",
        "  print(train_descriptions['2903617548_d3e38d7f88'][i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LX_1VzwIFXS"
      },
      "source": [
        "i=0\n",
        "for keys,values in train_descriptions.items():\n",
        " i=i+1\n",
        " \n",
        " print(keys)\n",
        " print(values)\n",
        " if i>20:break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3kMSRZ9IL9Z"
      },
      "source": [
        "# Data Preprocessing- Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJtqJS1kIFaU"
      },
      "source": [
        "from keras.applications.resnet50 import ResNet50, preprocess_input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbtmFjtdIFe-"
      },
      "source": [
        "model = ResNet50(weights = 'imagenet', input_shape = (224,224,3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlDfHR_rIFlq"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qa2WrcY-IFqo"
      },
      "source": [
        "model_new = Model(inputs = model.input, outputs =  model.layers[-2].output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMppb75CIFod"
      },
      "source": [
        "def preprocess_image(img):\n",
        "    img = image.load_img(img, target_size=(224,224))\n",
        "    img = image.img_to_array(img)\n",
        "    img = preprocess_input(img)\n",
        "    img = np.expand_dims(img, axis = 0)\n",
        "\n",
        "    return img\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69CJOEkpIjxf"
      },
      "source": [
        "def encode_image(img):\n",
        "    img = preprocess_image(img)\n",
        "    fea_vec = model_new.predict(img)\n",
        "    fea_vec = fea_vec.reshape(fea_vec.shape[1], )\n",
        "    return fea_vec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbKecCV7Ij7L"
      },
      "source": [
        "start = time.time()\n",
        "\n",
        "encoding_train = {}                #Dictionary with keys as image ids and values as encoding corresponding to the images                        \n",
        "\n",
        "for ix, img in enumerate(train):\n",
        "    \n",
        "    img = images+train[ix]+\".jpg\"\n",
        "    \n",
        "    p = encode_image(img)\n",
        "    \n",
        "    encoding_train[ img[len(images):] ] = p\n",
        "    \n",
        "    \n",
        "    if ix%100 == 0:\n",
        "        print(\"Encoding image :\" + str(ix))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xx4Kw26LbVEF"
      },
      "source": [
        "cd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPx2kMhrRGMb"
      },
      "source": [
        "start = time.time()\n",
        "\n",
        "encoding_test = {}\n",
        "\n",
        "for ix, img in enumerate(test):\n",
        "    \n",
        "    img = images+test[ix]+\".jpg\"\n",
        "    \n",
        "    p = encode_image(img)\n",
        "    \n",
        "    encoding_test[ img[len(images):] ] = p\n",
        "    \n",
        "    \n",
        "    if ix%100 == 0:\n",
        "        print(\"Encoding image :\" + str(ix))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0TTUXy8Ij_F"
      },
      "source": [
        "with open(\"/content/drive/MyDrive/drive-download-20210515T180709Z-001/encoded_train_images.pkl\", 'wb') as f:\n",
        "    pickle.dump(encoding_train, f )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzBYXDjXRnHi"
      },
      "source": [
        "with open(\"/content/drive/MyDrive/drive-download-20210515T180709Z-001/encoded_test_images.pkl\", 'wb') as f:\n",
        "    pickle.dump(encoding_test, f )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3l9C1J9IkQW"
      },
      "source": [
        "with open(\"/content/drive/MyDrive/drive-download-20210515T180709Z-001/encoded_train_images.pkl\", 'rb') as f:\n",
        "    encoding_train = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpECD6IbXaJA"
      },
      "source": [
        "with open(\"/content/drive/MyDrive/drive-download-20210515T180709Z-001/encoded_test_images.pkl\", 'rb') as f:\n",
        "    encoding_test = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFMGiFP6_3UQ"
      },
      "source": [
        "word_to_idx = {}\n",
        "idx_to_word = {}\n",
        "\n",
        "ix = 1\n",
        "\n",
        "for e in all_vocab:\n",
        "    #print(ix,e)\n",
        "    word_to_idx[e] = ix\n",
        "    idx_to_word[ix] = e\n",
        "    ix +=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cBvmGJjFMtN"
      },
      "source": [
        "i=0\n",
        "for keys,values in word_to_idx.items():\n",
        " i=i+1\n",
        " \n",
        " print(keys,values)\n",
        " \n",
        " if i>20:break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQkE5B3SFjgV"
      },
      "source": [
        "i=0\n",
        "for keys,values in idx_to_word.items():\n",
        " i=i+1\n",
        " \n",
        " print(keys,values)\n",
        " \n",
        " if i>20:break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkNXlWgdDyfq"
      },
      "source": [
        "for i in range(21):print(all_vocab[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_Tgqwy2_3RR"
      },
      "source": [
        "len(all_vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kyvd9T_MIj0x"
      },
      "source": [
        "vocab_size = len(idx_to_word) + 1\n",
        "print(vocab_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTadzqglDTAe"
      },
      "source": [
        "all_caption_len = []\n",
        "\n",
        "for key in train_descriptions.keys():\n",
        "    for cap in train_descriptions[key]:\n",
        "        all_caption_len.append(len(cap.split()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwEydUaLGX3P"
      },
      "source": [
        "print(len(all_caption_len))\n",
        "print(all_caption_len[:50])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBswhmdADS8U"
      },
      "source": [
        "max_len = max(all_caption_len)\n",
        "print(max_len) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1vDJntmIj5b"
      },
      "source": [
        "def data_generator(train_descriptions, encoding_train, word_to_idx, max_len,  num_photos_per_batch ):\n",
        "    X1, X2, y = [], [], []\n",
        "    \n",
        "    n=0\n",
        "    cnt = 0\n",
        "    all_items = list(train_descriptions.keys())\n",
        "    \n",
        "    while True:\n",
        "      n+=1\n",
        "      # print(cnt)\n",
        "      key = all_items[cnt]\n",
        "      desc_list = train_descriptions[key]              \n",
        "      cnt+=1\n",
        "      cnt= (cnt%len(all_items))\n",
        "\n",
        "\n",
        "      photo = encoding_train[key+'.jpg']          #feature vector\n",
        "            #print(photo.shape)\n",
        "      for desc in desc_list:                       #desc : iterates through the 5 captions\n",
        "        seq = [word_to_idx[word] for word in desc.split() if word in word_to_idx]                \n",
        "                \n",
        "        for i in range(1, len(seq)): \n",
        "            in_seq = seq[0:i]\n",
        "            out_seq = seq[i]\n",
        "            \n",
        "            in_seq = pad_sequences( [in_seq], maxlen=max_len, value= 0, padding='post')[0]\n",
        "        \n",
        "            out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
        "            \n",
        "            X1.append(photo)\n",
        "            X2.append(in_seq)\n",
        "            y.append(out_seq)\n",
        "\n",
        "      if n == num_photos_per_batch:\n",
        "          yield [np.array(X1), np.array(X2)] , np.array(y)\n",
        "          X1, X2, y = [], [], []\n",
        "          n = 0         "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvWhDAmt_3Xa"
      },
      "source": [
        "for i in data_generator(train_descriptions, encoding_train, word_to_idx, max_len, 3):\n",
        "    X, y = i\n",
        "    print(X[0].shape) \n",
        "    print(X[1].shape)\n",
        "    print(y.shape)\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seVTvGYhDS25"
      },
      "source": [
        "embeddings = {}\n",
        "\n",
        "with open('/content/drive/MyDrive/glove.6B.50d.txt', 'r', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coeffs = np.array(values[1:], dtype=\"float32\")\n",
        "        \n",
        "        embeddings[word] = coeffs\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8URql56-J87_"
      },
      "source": [
        "i=0\n",
        "for keys,values in embeddings.items():\n",
        " i=i+1\n",
        " \n",
        " print(keys,values)\n",
        " \n",
        " if i>10:break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIpYT-LcKN98"
      },
      "source": [
        "print(len(embeddings))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXt5_Y_cRQVN"
      },
      "source": [
        "def getOutputEmbeddings():\n",
        "\n",
        "    emb_dim = 50\n",
        "    embedding_matrix_output = np.zeros((vocab_size, emb_dim ))\n",
        "    \n",
        "    for word, idx in word_to_idx.items():\n",
        "        \n",
        "        emb_vec = embeddings.get(word)\n",
        "        \n",
        "        if emb_vec is not None:\n",
        "            embedding_matrix_output[idx] = emb_vec\n",
        "            \n",
        "    return embedding_matrix_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFoBXwgORVxZ"
      },
      "source": [
        "embedding_output = getOutputEmbeddings()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwTW-2RtRVuW"
      },
      "source": [
        "embedding_output.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzqVIWAEKums"
      },
      "source": [
        "print(embedding_output[3:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyaTwLCWRVqe"
      },
      "source": [
        "input_img_fea = Input(shape=(2048,))\n",
        "inp_img1 = Dropout(0.5)(input_img_fea)\n",
        "inp_img2 = Dense(256, activation='relu')(inp_img1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiAPbieBLxcW"
      },
      "source": [
        "print(inp_img2.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ng1HoL0iRVmC"
      },
      "source": [
        "input_cap = Input(shape=(max_len,))\n",
        "inp_cap1 = Embedding(input_dim= vocab_size, output_dim=50, mask_zero=True)(input_cap)\n",
        "#print(inp_cap1)\n",
        "inp_cap2 = Dropout(0.5)(inp_cap1)\n",
        "inp_cap3 = LSTM(256)(inp_cap2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlWFbN0cL3n7"
      },
      "source": [
        "print(inp_cap3.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evkP2ZyL7MmC"
      },
      "source": [
        "decoder1 = add([inp_img2, inp_cap3])\n",
        "print(decoder1.shape)\n",
        "decoder2 = Dense(256, activation='relu')(decoder1)\n",
        "output = Dense(vocab_size, activation='softmax')(decoder2)\n",
        "\n",
        "\n",
        "model = Model(inputs = [input_img_fea, input_cap]  , outputs =  output )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPs-L61t7Mhs"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MM1Xcilm7Md7"
      },
      "source": [
        "model.layers[2].set_weights([embedding_output])\n",
        "model.layers[2].trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbKZlHQa7MZK"
      },
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer='adam') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykJKMaPW7MRO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5be21a8-3778-41bd-b83f-8a576c5bb5b7"
      },
      "source": [
        "epochs = 30\n",
        "number_photos_per_batch = 50\n",
        "steps = len(train_descriptions)//number_photos_per_batch\n",
        "\n",
        "mytraingen = data_generator(train_descriptions, encoding_train, word_to_idx, max_len, number_photos_per_batch)\n",
        "\n",
        "model.fit(mytraingen,steps_per_epoch=steps,epochs = epochs,verbose=1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "120/120 [==============================] - 613s 5s/step - loss: 2.9662\n",
            "Epoch 13/30\n",
            "120/120 [==============================] - 621s 5s/step - loss: 2.9327\n",
            "Epoch 14/30\n",
            "120/120 [==============================] - 620s 5s/step - loss: 2.9020\n",
            "Epoch 15/30\n",
            "120/120 [==============================] - 628s 5s/step - loss: 2.8722\n",
            "Epoch 16/30\n",
            "120/120 [==============================] - 622s 5s/step - loss: 2.8465\n",
            "Epoch 17/30\n",
            "120/120 [==============================] - 620s 5s/step - loss: 2.8249\n",
            "Epoch 18/30\n",
            "120/120 [==============================] - 617s 5s/step - loss: 2.8039\n",
            "Epoch 19/30\n",
            "120/120 [==============================] - 620s 5s/step - loss: 2.7847\n",
            "Epoch 20/30\n",
            "120/120 [==============================] - 618s 5s/step - loss: 2.7662\n",
            "Epoch 21/30\n",
            " 20/120 [====>.........................] - ETA: 8:32 - loss: 2.7587"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKOCgzj-9lvb"
      },
      "source": [
        "model.save(\"final_model.h5\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTTQL0-BNwH4"
      },
      "source": [
        "model.save_weights(\"/content/drive/MyDrive/drive-download-20210515T180709Z-001/weights.h5\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FzhBGxZs91z"
      },
      "source": [
        "model=load_model('/content/final_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upkNSXpeq0PG"
      },
      "source": [
        "# Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BW2VatATA2y"
      },
      "source": [
        "def predict(photo_enc,model):\n",
        "    in_text = \"<startseq>\"\n",
        "    \n",
        "    for i in range(max_len):\n",
        "        sequence = [word_to_idx[word] for word in in_text.split() if word in word_to_idx]\n",
        "        #print(sequence)\n",
        "        sequence = pad_sequences([sequence], maxlen=max_len, padding='post')\n",
        "        \n",
        "        y_pred = model.predict([photo_enc, sequence])\n",
        "        y_pred = np.argmax(y_pred)\n",
        "        word = idx_to_word[y_pred]\n",
        "        \n",
        "        in_text += \" \"+word\n",
        "        \n",
        "        if word == '<endseq>':\n",
        "            break\n",
        "        \n",
        "        \n",
        "    final_caption = in_text.split()\n",
        "    final_caption = final_caption[1:-1]\n",
        "    final_caption = \" \".join(final_caption)\n",
        "    return final_caption"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fc0-eVwV6ua"
      },
      "source": [
        "one=encode_image('/content/sample1.jpg').reshape((1,2048))\n",
        "print(one)\n",
        "img = plt.imread('/content/sample1.jpg')\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "predict1=predict(one,model)\n",
        "print(predict1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jblN0PQWy6i"
      },
      "source": [
        "two=encode_image('/content/sample2.jpg').reshape((1,2048))\n",
        "print(two)\n",
        "img = plt.imread('/content/sample2.jpg')\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "predict2=predict(two,model)\n",
        "print(predict2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lj3AzzVYWzxW"
      },
      "source": [
        "three=encode_image('/content/sample3.jpg').reshape((1,2048))\n",
        "print(three)\n",
        "img = plt.imread('/content/sample3.jpg')\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "predict3=predict(three,model)\n",
        "print(predict3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5g-RafIfW0nP"
      },
      "source": [
        "four=encode_image('/content/sample4.jpg').reshape((1,2048))\n",
        "print(four)\n",
        "img = plt.imread('/content/sample4.jpg')\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "predict4=predict(four,model)\n",
        "print(predict4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7i6T-_CwW1xB"
      },
      "source": [
        "five=encode_image('/content/sample5.jpg').reshape((1,2048))\n",
        "print(five)\n",
        "img = plt.imread('/content/sample5.jpg')\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "predict5=predict(five,model)\n",
        "print(predict5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OBm2E4B0bOS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}